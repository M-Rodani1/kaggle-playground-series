{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:13:01.060586Z",
     "start_time": "2025-12-02T18:13:00.676635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KAGGLE NOVEMBER 2025 - IMPROVED PIPELINE\n",
    "# Multi-Seed + External Data Augmentation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "id": "23de48fbcc76e7cb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:13:09.412603Z",
     "start_time": "2025-12-02T18:13:09.409548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CONFIGURATION\n",
    "\n",
    "\n",
    "# File paths\n",
    "TRAIN_PATH = 'train.csv'\n",
    "TEST_PATH = 'test.csv'\n",
    "ORIG_PATH = 'loan_dataset_20000.csv'\n",
    "\n",
    "# Training configuration\n",
    "SEEDS = [42, 43, 44, 45, 46]  # Multi-seed for variance reduction\n",
    "N_SPLITS = 5  # Stratified K-Fold\n",
    "TARGET = 'loan_paid_back'\n",
    "\n",
    "# LightGBM parameters (from your Optuna optimization)\n",
    "LGBM_PARAMS = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.04619852582842627,\n",
    "    'num_leaves': 57,\n",
    "    'max_depth': 12,\n",
    "    'min_child_samples': 190,\n",
    "    'subsample': 0.7152363987011763,\n",
    "    'colsample_bytree': 0.6517074545892816,\n",
    "    'lambda_l1': 4.023591669670226,\n",
    "    'lambda_l2': 3.995624195713791,\n",
    "    'min_split_gain': 0.1165571634393688,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "print(f\"   Seeds: {SEEDS}\")\n",
    "print(f\"   CV folds: {N_SPLITS}\")\n",
    "print(f\"   LightGBM learning_rate: {LGBM_PARAMS['learning_rate']:.4f}\")"
   ],
   "id": "80d85a8b2f2e9f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Seeds: [42, 43, 44, 45, 46]\n",
      "   CV folds: 5\n",
      "   LightGBM learning_rate: 0.0462\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:13:13.775274Z",
     "start_time": "2025-12-02T18:13:13.279331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LOAD DATA\n",
    "\n",
    "# Load train and test\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "orig = pd.read_csv(ORIG_PATH)\n",
    "\n",
    "print(f\" Train shape: {train.shape}\")\n",
    "print(f\" Test shape: {test.shape}\")\n",
    "print(f\" Original dataset shape: {orig.shape}\")\n",
    "\n",
    "print(f\"\\nTarget distribution (train):\")\n",
    "print(train[TARGET].value_counts(normalize=True))\n",
    "\n",
    "print(f\"\\nTarget distribution (original):\")\n",
    "print(orig[TARGET].value_counts(normalize=True))"
   ],
   "id": "e78d5aa02ce1795e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train shape: (593994, 13)\n",
      " Test shape: (254569, 12)\n",
      " Original dataset shape: (20000, 22)\n",
      "\n",
      "Target distribution (train):\n",
      "loan_paid_back\n",
      "1.0    0.79882\n",
      "0.0    0.20118\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target distribution (original):\n",
      "loan_paid_back\n",
      "1    0.7999\n",
      "0    0.2001\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:13:17.909283Z",
     "start_time": "2025-12-02T18:13:17.241082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# EXTERNAL DATA AUGMENTATION\n",
    "# Categorical features to augment\n",
    "cat_features = ['gender', 'marital_status', 'education_level',\n",
    "                'employment_status', 'loan_purpose', 'grade_subgrade']\n",
    "\n",
    "external_features = []\n",
    "\n",
    "for col in cat_features:\n",
    "    print(f\"\\nProcessing {col}...\")\n",
    "\n",
    "    # Calculate statistics from original dataset\n",
    "    orig_stats = orig.groupby(col)[TARGET].agg(['mean', 'std', 'count'])\n",
    "\n",
    "    # Create feature names\n",
    "    mean_col = f'orig_mean_{col}'\n",
    "    std_col = f'orig_std_{col}'\n",
    "    count_col = f'orig_count_{col}'\n",
    "\n",
    "    # Map to train\n",
    "    train[mean_col] = train[col].map(orig_stats['mean'])\n",
    "    train[std_col] = train[col].map(orig_stats['std'])\n",
    "    train[count_col] = train[col].map(orig_stats['count'])\n",
    "\n",
    "    # Map to test\n",
    "    test[mean_col] = test[col].map(orig_stats['mean'])\n",
    "    test[std_col] = test[col].map(orig_stats['std'])\n",
    "    test[count_col] = test[col].map(orig_stats['count'])\n",
    "\n",
    "    # Fill NaN with global statistics\n",
    "    global_mean = orig[TARGET].mean()\n",
    "    global_std = orig[TARGET].std()\n",
    "\n",
    "    for df in [train, test]:\n",
    "        df[mean_col].fillna(global_mean, inplace=True)\n",
    "        df[std_col].fillna(global_std, inplace=True)\n",
    "        df[count_col].fillna(0, inplace=True)\n",
    "\n",
    "    external_features.extend([mean_col, std_col, count_col])\n",
    "    print(f\"   Created: {mean_col}, {std_col}, {count_col}\")\n",
    "\n",
    "print(f\" Created {len(external_features)} external features\")\n",
    "\n",
    "# Correlation check\n",
    "print(\"\\n Correlation check (external vs base features):\")\n",
    "base_numerical = ['annual_income', 'loan_amount', 'credit_score',\n",
    "                  'debt_to_income_ratio', 'interest_rate']\n",
    "\n",
    "for i, ext_feat in enumerate(external_features[:6]):  # Show first 6\n",
    "    max_corr = train[[ext_feat] + base_numerical].corr()[ext_feat][1:].abs().max()\n",
    "    status = \"\" if max_corr < 0.9 else \"\"\n",
    "    print(f\"  {status} {ext_feat[:35]:35s} max_r = {max_corr:.4f}\")\n",
    "\n",
    "print(\"\\nExternal data augmentation complete!\")"
   ],
   "id": "48688b9c794e2d8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing gender...\n",
      "   Created: orig_mean_gender, orig_std_gender, orig_count_gender\n",
      "\n",
      "Processing marital_status...\n",
      "   Created: orig_mean_marital_status, orig_std_marital_status, orig_count_marital_status\n",
      "\n",
      "Processing education_level...\n",
      "   Created: orig_mean_education_level, orig_std_education_level, orig_count_education_level\n",
      "\n",
      "Processing employment_status...\n",
      "   Created: orig_mean_employment_status, orig_std_employment_status, orig_count_employment_status\n",
      "\n",
      "Processing loan_purpose...\n",
      "   Created: orig_mean_loan_purpose, orig_std_loan_purpose, orig_count_loan_purpose\n",
      "\n",
      "Processing grade_subgrade...\n",
      "   Created: orig_mean_grade_subgrade, orig_std_grade_subgrade, orig_count_grade_subgrade\n",
      " Created 18 external features\n",
      "\n",
      " Correlation check (external vs base features):\n",
      "   orig_mean_gender                    max_r = 0.0049\n",
      "   orig_std_gender                     max_r = 0.0050\n",
      "   orig_count_gender                   max_r = 0.0049\n",
      "   orig_mean_marital_status            max_r = 0.0051\n",
      "   orig_std_marital_status             max_r = 0.0051\n",
      "   orig_count_marital_status           max_r = 0.0094\n",
      "\n",
      "External data augmentation complete!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:13:23.446481Z",
     "start_time": "2025-12-02T18:13:22.797615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# PREPROCESSING\n",
    "\n",
    "# Create copies\n",
    "train_df = train.copy()\n",
    "test_df = test.copy()\n",
    "\n",
    "# Save ID for submission\n",
    "test_ids = test_df['id'].copy()\n",
    "\n",
    "# Drop ID\n",
    "train_df.drop(columns=['id'], inplace=True)\n",
    "test_df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "cat_cols = ['gender', 'marital_status', 'education_level',\n",
    "            'employment_status', 'loan_purpose', 'grade_subgrade']\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    combined = pd.concat([train_df[col], test_df[col]]).astype(str)\n",
    "    le.fit(combined)\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "    print(f\"Encoded {col}\")\n",
    "\n",
    "# Create feature matrix and target\n",
    "X = train_df.drop(columns=[TARGET])\n",
    "y = train_df[TARGET]\n",
    "X_test = test_df.copy()\n",
    "\n",
    "\n",
    "print(\"Preprocessing complete\")\n",
    "print(f\"Total features: {X.shape[1]}\")\n",
    "print(f\"  - Base features: 11\")\n",
    "print(f\"  - External features: {len(external_features)}\")\n",
    "print(f\"Samples: {X.shape[0]} train, {X_test.shape[0]} test\")"
   ],
   "id": "a74ede9a5c37fe6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded gender\n",
      "Encoded marital_status\n",
      "Encoded education_level\n",
      "Encoded employment_status\n",
      "Encoded loan_purpose\n",
      "Encoded grade_subgrade\n",
      "Preprocessing complete\n",
      "Total features: 29\n",
      "  - Base features: 11\n",
      "  - External features: 18\n",
      "Samples: 593994 train, 254569 test\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:13:26.204976Z",
     "start_time": "2025-12-02T18:13:26.200895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TRAINING FUNCTION\n",
    "\n",
    "def train_lgbm_single_seed(X, y, X_test, params, seed, n_splits=5):\n",
    "    \"\"\"\n",
    "    Train LightGBM with a single seed using K-Fold CV\n",
    "\n",
    "    Returns:\n",
    "        oof_preds: Out-of-fold predictions on train\n",
    "        test_preds: Predictions on test\n",
    "        cv_score: Cross-validation AUC score\n",
    "    \"\"\"\n",
    "    # Update seed\n",
    "    params_seed = params.copy()\n",
    "    params_seed['random_state'] = seed\n",
    "\n",
    "    # Initialize predictions\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "\n",
    "    # Stratified K-Fold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    fold_scores = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        # Split data\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # Train model\n",
    "        model = lgb.LGBMClassifier(**params_seed)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "        )\n",
    "\n",
    "        # Predict\n",
    "        oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_splits\n",
    "\n",
    "        # Score\n",
    "        fold_auc = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "        fold_scores.append(fold_auc)\n",
    "\n",
    "    # Calculate overall CV\n",
    "    cv_score = roc_auc_score(y, oof_preds)\n",
    "\n",
    "    return oof_preds, test_preds, cv_score\n"
   ],
   "id": "26c4272d6aec6c09",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:22:16.710369Z",
     "start_time": "2025-12-02T18:13:29.894090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# MULTI-SEED TRAINING\n",
    "\n",
    "\n",
    "print(\"\\nTraining LightGBM with multi-seed averaging\")\n",
    "\n",
    "all_oof = []\n",
    "all_test = []\n",
    "all_cv = []\n",
    "\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"\\n Seed {i+1}/{len(SEEDS)}: {seed}\")\n",
    "    oof, test, cv = train_lgbm_single_seed(\n",
    "        X, y, X_test,\n",
    "        LGBM_PARAMS,\n",
    "        seed,\n",
    "        n_splits=N_SPLITS\n",
    "    )\n",
    "\n",
    "    all_oof.append(oof)\n",
    "    all_test.append(test)\n",
    "    all_cv.append(cv)\n",
    "\n",
    "    print(f\"   CV AUC: {cv:.6f}\")\n",
    "\n",
    "# Average predictions\n",
    "oof_final = np.mean(all_oof, axis=0)\n",
    "test_final = np.mean(all_test, axis=0)\n",
    "cv_final = roc_auc_score(y, oof_final)\n",
    "\n",
    "print(\"multi seed results\")\n",
    "print(f\"\\nIndividual CVs:\")\n",
    "for i, cv in enumerate(all_cv):\n",
    "    print(f\"  Seed {SEEDS[i]}: {cv:.6f}\")\n",
    "\n",
    "print(f\"\\nMean of individuals: {np.mean(all_cv):.6f} ± {np.std(all_cv):.6f}\")\n",
    "print(f\"Multi-seed ensemble: {cv_final:.6f}\")\n",
    "print(f\"Gain from averaging: +{cv_final - np.mean(all_cv):.6f}\")\n"
   ],
   "id": "afe7af41b34d734b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LightGBM with multi-seed averaging\n",
      "\n",
      " Seed 1/5: 42\n",
      "   CV AUC: 0.923178\n",
      "\n",
      " Seed 2/5: 43\n",
      "   CV AUC: 0.923035\n",
      "\n",
      " Seed 3/5: 44\n",
      "   CV AUC: 0.923323\n",
      "\n",
      " Seed 4/5: 45\n",
      "   CV AUC: 0.923196\n",
      "\n",
      " Seed 5/5: 46\n",
      "   CV AUC: 0.923245\n",
      "multi seed results\n",
      "\n",
      "Individual CVs:\n",
      "  Seed 42: 0.923178\n",
      "  Seed 43: 0.923035\n",
      "  Seed 44: 0.923323\n",
      "  Seed 45: 0.923196\n",
      "  Seed 46: 0.923245\n",
      "\n",
      "Mean of individuals: 0.923195 ± 0.000094\n",
      "Multi-seed ensemble: 0.923682\n",
      "Gain from averaging: +0.000487\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:22:54.695172Z",
     "start_time": "2025-12-02T18:22:54.457348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CREATE SUBMISSION\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    TARGET: test_final\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_improved.csv', index=False)\n",
    "print(f\"File: submission_improved.csv\")\n",
    "print(f\"Rows: {len(submission)}\")\n",
    "print(f\"\\nSample predictions:\")\n",
    "print(submission.head())"
   ],
   "id": "cf447da80f692f9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: submission_improved.csv\n",
      "Rows: 254569\n",
      "\n",
      "Sample predictions:\n",
      "       id  loan_paid_back\n",
      "0  593994        0.932328\n",
      "1  593995        0.978760\n",
      "2  593996        0.529594\n",
      "3  593997        0.908904\n",
      "4  593998        0.968299\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T18:23:13.172582Z",
     "start_time": "2025-12-02T18:23:13.169605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# COMPARISON WITH BASELINE\n",
    "\n",
    "baseline_cv = 0.92321  # Your Phase 1 baseline\n",
    "\n",
    "\n",
    "print(\"improvement summary\")\n",
    "print(f\"\\nBaseline (single LGB):           {baseline_cv:.6f}\")\n",
    "print(f\"New pipeline (multi-seed + ext): {cv_final:.6f}\")\n",
    "print(f\"Improvement:                     +{cv_final - baseline_cv:.6f} ({((cv_final/baseline_cv - 1)*100):.2f}%)\")\n",
    "\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"  Base features:      11\")\n",
    "print(f\"  External features:  {len(external_features)}\")\n",
    "print(f\"  Total features:     {X.shape[1]}\")\n",
    "\n",
    "\n"
   ],
   "id": "cc657acca2403a40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improvement summary\n",
      "\n",
      "Baseline (single LGB):           0.923210\n",
      "New pipeline (multi-seed + ext): 0.923682\n",
      "Improvement:                     +0.000472 (0.05%)\n",
      "\n",
      "Feature breakdown:\n",
      "  Base features:      11\n",
      "  External features:  18\n",
      "  Total features:     29\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
